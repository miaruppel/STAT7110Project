sample(subset4, size=10, replace=FALSE)
paste(variable1, ' is equal to ', variable1)
variable1 <- 5
paste(variable1, ' is equal to ', variable1)
paste(variable1, 'is equal to', variable1)
ls()
matrix1 <- matrix(data=1, nrow=3, ncol=3)
matrix1
matrix2 <- matrix(NA, 3, 7)
matrix2
dim(matrix2)
vector8 <- 1:12
matrix3 <- matrix(data=vector8, nrow=4)
matrix3
matrix4 <- matrix(data=vector8, nrow=4, byrow=TRUE)
matrix4
vector9 <- 1:10
vector10 <- vector9^2
matrix5 <- rbind(vector9, vector10)
matrix5
matrix6 <- cbind(vector9, vector10, vector9) # stacks vectors horizontally
matrix6
colnames(matrix6) <- c('A', 'B', 'C')
rownames(matrix6) <- c('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j')
matrix6
matrix7 <- diag(5)
matrix7
vector11 <- c(1,2,3,4,5)
matrix8 <- diag(vector11)
matrix8
diag(matrix8)
matrix9 <- matrix(1:9, 3)
matrix9
matrix9[1,1] # extracts the 1st element of the 1st row
matrix9[2,3] # extracts the 3rd element of the 2nd row
matrix9[ ,1]
x <- matrix(1:4, nrow=2)
x
y <- diag(2)
y
x*y
x %*% y
t(x)
eigen(x)
names(eigen.list)
eigen.list$vectors
names(Eigen.List)
Eigen.List$vectors
constant <- rep(1, times=10)
variable <- c(1,2,3,1,2,3,5,6,7,8)
X <- cbind(constant, variable)
Y <- seq(1,10)
Beta.Hats <- solve(t(X) %*% X) %*% (X) %*% Y
colnames(Beta.Hats) <- 'Estimate'
Beta.Hats
constant <- rep(1, times=10)
variable <- c(1,2,3,1,2,3,5,6,7,8)
X <- cbind(constant, variable)
Y <- seq(1,10)
Beta.Hats <- solve(t(X) %*% X) %*% t(X) %*% Y
colnames(Beta.Hats) <- 'Estimate'
Beta.Hats
# titanic example
require(graphics)
mosaicplot(Titanic, main = "Survival on the Titanic")
## Higher survival rates in children?
apply(Titanic, c(3, 4), sum)
mydata <- airquality
View(mydata)
summary(mydata)
summary(mydata, digits=1)
sapply(mydata, FUN=mean)
sapply(mydata, FUN=mean, na.rm=T) # removing NA values
lapply(mydata, FUN=mean, na.rm=T) # gives in list format
library(Hmisc)
describe(mydata)
library(pastecs)
stat.desc(mydata, basic=TRUE, desc=TRUE, norm=FALSE, p=0.95)
stat.desc(mydata, basic=F) # descriptive stats only
stat.desc(mydata, desc=F) # basic stats only
stat.desc(mydata, basic=F, desc=F, norm=T)  # normal distribution stats only
?pastecs::stat.desc
mydata <- mtcars[c("mpg", "hp", "wt")]
View(mydata)
aggregate(mydata, by=list(mtcars$am), FUN=mean)
aggregate(mydata, by=list(am = mtcars$am), FUN=mean)
library(psych)
describeBy(mydata, group=list(am = mtcars$am))
# Test if the average mpg is 20 (H0: mu=20)
result <- t.test(mtcars$mpg, mu=20)
result
result$conf.int
result$estimate
# Test if there is any mean mpg differences between automatic (am=0) and manual (am=1)
t.test(mpg ~ am, data=mtcars)
# with equal variances between automatic and manual
t.test(mpg ~ am, var.equal=T, data=mtcars)
t.test(mpg ~ am,
alternative="less", # automatic is less than
var.equal=T,
data=mtcars)
#############
# Test of homogeneity (H0: var1 = var2)
# to see if variance is equal
bartlett.test(mpg ~ am, data=mtcars)
#############
# paired t-test
# Student's sleep data
# Data which show the effect of two soporific drugs (increase in hours of sleep compared to control) on 10 patients.
sleep
t.test(extra ~ group, data=sleep)   # wrong way!
t.test(extra ~ group, data=sleep, paired = T)
#############
# Normality Test
shapiro.test(mtcars$mpg)
wilcox.test(mtcars$mpg, mu=20)
wilcox.test(mtcars$mpg,
mu=20,
exact = F)
wilcox.test(mpg ~ am, exact=F, data=mtcars)
wilcox.test(extra ~ group, exact=F, paired = T, data=sleep)
cov(mtcars)
cor(mtcars)
cov(airquality)   # NA due to missing values
cov(airquality,
use = "complete.obs", # removes missing values
method = "pearson")
datasets::rock
mydata <- datasets::rock
View(mydata)
stat.desc(mydata, basic=TRUE, desc=TRUE, norm=FALSE, p=0.95)
stat.desc(mydata, basic=F, desc=F, norm=T)  # normal distribution stats only
# report the sd of the variable area when perm=100
values <- c(1468, 3524, 3469, 5267)
sd(values)
?t.test
# report p value the test whether the average area is less than 8000
result <- t.test(mydata$area, alternative='less')
result
mean(mydata$area)
# report p value the test whether the average area is less than 8000
result <- t.test(mydata$area, mu=8000, alternative='less')
result
stat.desc(mydata, basic=F) # descriptive stats only
stat.desc(mydata, basic=TRUE, desc=TRUE, norm=FALSE, p=0.95)
stat.desc(mydata, basic=F) # descriptive stats only
stat.desc(mydata, desc=F) # basic stats only
# 99% confidence interval of the population mean area
stat.desc(mydata, basic=F, p=.99)
# 99% confidence interval of the population mean area
stat.desc(mydata, basic=F, p=.99)
sapply(mydata, FUN=mean) # mean for every variable
sapply(mydata, FUN=mean, na.rm=T) # removing NA values
describe(mydata) # also gives basic statistics
summary(mydata)
?pastecs::stat.desc
# 99% confidence interval of the population mean area
t.test(mydata$area, mu=mean(mydata$area), p=.99)
?t.test
# 99% confidence interval of the population mean area
t.test(mydata$area, mu=mean(mydata$area), conf.level=.99)
# report the sd of the variable area when perm=100
values1 <- c(1468, 3524, 3469, 5267)
# report the p value whether the population mean area in perm=100 and perm=1300
# are the same or not
# test equal variances first
values2 <- c(1016, 5048, 5605, 8793)
bartlett.test(values1 ~ values2)
# which variables follow a normal distribution?
shapiro.test(mydata$area)
shapiro.test(mydata$peri)
shapiro.test(mydata$shape)
shapiro.test(mydata$perm)
# report the covariance between shape and perm
cov(mydata)
# report the covariance between shape and perm
cov(mydata)
# report pearson coefficient of correlation between shape and perm
cor(mydata)
stat.desc(mydata, basic=F, desc=F, norm=T)
# OR
sapply(mydata, FUN=skew)
bartlett.test(area ~ perm, data=mydata.all)
bartlett.test(area ~ perm, data=mydata)
# big p value, assume equal variance
t.test(area ~ perm, var.equal=TRUE, data=mydata)
# big p value, assume equal variance
t.test(area ~ perm, var.equal=TRUE, data=mydata.all)
mydata.all
###############
# Confidence Interval
# Toss 20 coins 50 times, compute proportions, and compute SE (standard error)
# example for central limit theorem
m = 100; n=20; p = .5;         # toss 20 coins 50 times
phat = rbinom(m,n,p)/n        # divide by n for proportions
rm(list=ls())
###############
# Confidence Interval
# Toss 20 coins 50 times, compute proportions, and compute SE (standard error)
# example for central limit theorem
m = 100; n=20; p = .5;         # toss 20 coins 50 times
phat = rbinom(m,n,p)/n        # divide by n for proportions
phat
SE = sqrt(phat*(1-phat)/n)    # compute standard error
round(SE, 4)
# Let alpha = 0.1 and plot CIs
alpha = 0.05; zstar = qnorm(1-alpha/2)
matplot(rbind(phat - zstar*SE, phat + zstar*SE),
rbind(1:m,1:m),type="l",lty=1, xlab="Probability", ylab="")
abline(v=p)                  # draw line for p=0.5
###############
# Simple frequency distribution
( tmp <- rpois(100, 5) )
table(tmp)
table(mtcars$cyl)
with(mtcars, table(cyl))
attach(mtcars)
( mytable <- table(cyl, gear) )
margin.table(mytable, 1) # 1 for rows: A frequencies (summed over B)
margin.table(mytable, 2) # 2 for columns: B frequencies (summed over A)
prop.table(mytable) # cell percentages
prop.table(mytable, 1) # row percentages
prop.table(mytable, 2) # column percentages
detach(mtcars)
###############
# 3-Way Frequency Table
example <- data.frame(
Hospital = sample(as.factor(paste("H",1:5)), size = 10, replace = TRUE),
Time = sample(as.factor(c(" 2000", " 2003", " 2006")), size = 10, replace = TRUE),
Nodes = sample(1:5, size = 10, replace = TRUE)
)
example
table(example)
ftable(example)
names(example)
Titanic
str(Titanic)
ftable(Titanic, row.vars = 1:3)
ftable(Titanic, row.vars = 1:2, col.vars = "Survived") # class and sex, column variable is survived only
ftable(Titanic, row.vars = 2:1, col.vars = "Survived") # change order of sex and class
## Start with a data frame.
x <- ftable(mtcars[c("cyl", "vs", "am", "gear")])
x
ftable(x, row.vars = c(2, 4))
library(gmodels)
CrossTable(example$Hospital, example$Time)
( heads <- rbinom(1, size=100, prob = .5) )  # p-hat=heads/size
?prop.test
prop.test(10, 100)          # continuity correction TRUE by default
prop.test(heads, 100, correct = FALSE)
prop.test(heads, 100, alternative="greater")
prop.test(heads, 100, alternative="less")
prop.test(heads, 100, alternative="two.sided")
prop.test(heads,100, conf.level=0.90)
prop.test(heads,100, conf.level=0.99)
( X <- c(A = 20, B = 15, C = 25) )
(Xsq <- chisq.test(X))  # Prints test summary
Xsq$observed   # observed counts (same as M)
Xsq$expected   # expected counts under the null
Xsq$residuals  # Pearson residuals
Xsq$stdres     # standardized residuals
Xsq$p.value
x <- c(59, 57, 16)
p <- c(.4, .5, .1)
chisq.test(x, p = p)
p <- c(4, 5, 1)
chisq.test(x, p=p, rescale.p=T)
x <- trunc(5 * runif(100))
x; table(x)
chisq.test(table(x))            # NOT 'chisq.test(x)'!
M <- as.table(rbind(c(762, 327, 468), c(484, 239, 477)))
dimnames(M) <- list(gender = c("M","F"),
party = c("Democrat","Independent", "Republican"))
M
(Xsq <- chisq.test(M))  # Prints test summary
Xsq$expected   # expected counts under the null
TeaTasting <-
matrix(c(3, 1, 1, 3),
nrow = 2,
dimnames = list(Guess = c("Milk", "Tea"),
Truth = c("Milk", "Tea")))
View(TeaTasting)
fisher.test(TeaTasting, alternative = "greater")
Job <- matrix(c(1,2,1,0, 3,3,6,1, 10,10,14,9, 6,7,12,11), 4, 4,
dimnames = list(income = c("< 15k", "15-25k", "25-40k", "> 40k"),
satisfaction = c("VeryD", "LittleD", "ModerateS", "VeryS")))
View(Job)
chisq.test(Job)
chisq.test(Job)$expected
fisher.test(Job)
###############
# Job Satisfaction example
# H0: there is no association by gender and income on job satisfaction
Satisfaction <-
as.table(array(c(1, 2, 0, 0, 3, 3, 1, 2,
11, 17, 8, 4, 2, 3, 5, 2,
1, 0, 0, 0, 1, 3, 0, 1,
2, 5, 7, 9, 1, 1, 3, 6),
dim = c(4, 4, 2),
dimnames =
list(Income =
c("<5000", "5000-15000",
"15000-25000", ">25000"),
"Job Satisfaction" =
c("V_D", "L_S", "M_S", "V_S"),
Gender = c("Female", "Male"))))
Satisfaction
## (Satisfaction categories abbreviated for convenience.)
ftable(. ~ Gender + Income, Satisfaction)
mantelhaen.test(Satisfaction)
mantelhaen.test(Satisfaction)
# big p value, no association between gender and income for job satisfaction
mantelhaen.test(Satisfaction)
# big p value, no association between gender and income for job satisfaction
# Does weight come from a normal with mean=120 and sd=15?
ks.test(women$weight, "pnorm", mean=120, sd=15)
# Does weight come from a normal with mean=135 and sd=15?
ks.test(women$weight, "pnorm", mean=135, sd=15)
# 59 accidents during the weekend among 114 bicycle accidents
# test if the proportion of bicycle accidents during the weekend is less than .60
# report the p value with continutity correction
prop.test(59, 114, correct=TRUE)
rm(list=ls())
# determine the proportion of males with brown hair and green eyes
mydata <- datasets::HairEyeColor
mydata
M <- as.table(rbind(c(762, 327, 468), c(484, 239, 477)))
dimnames(M) <- list(gender = c("M","F"),
party = c("Democrat","Independent", "Republican"))
M
###############
# Job Satisfaction example
# H0: there is no association by gender and income on job satisfaction
Satisfaction <-
as.table(array(c(1, 2, 0, 0, 3, 3, 1, 2,
11, 17, 8, 4, 2, 3, 5, 2,
1, 0, 0, 0, 1, 3, 0, 1,
2, 5, 7, 9, 1, 1, 3, 6),
dim = c(4, 4, 2),
dimnames =
list(Income =
c("<5000", "5000-15000",
"15000-25000", ">25000"),
"Job Satisfaction" =
c("V_D", "L_S", "M_S", "V_S"),
Gender = c("Female", "Male"))))
# three way table
Satisfaction
## (Satisfaction categories abbreviated for convenience.)
ftable(. ~ Gender + Income, Satisfaction)
# use this test for three way table
mantelhaen.test(Satisfaction)
ftable(. ~ Hair + Eyes, mydata)
?mantelhaen.test
mantelhaen.test(mydata)
table(mydata)
ftable(mydata)
ftable(mydata)
ftable(mydata)
names(mydata)
prop.table(mydata, 2)
prop.table(mydata)
prop.table(mydata)
# test if female is more than half the group
prop.test(mydata)
# test if female is more than half the group
ftable(mydata)
fisher.test(mydata,, alternative='greater')
fisher.test(mydata, alternative='greater')
chisq.test(mydata)
mydata
v1 <- c(7, 4, 87, 102, 12, 7, 9, 8)
?matrix
m1 <- maxtrix(v1, ncol=2)
m1 <- matrix(v1, ncol=2)
View(m1)
m1 <- matrix(v1, byrow=TRUE, ncol=2)
View(m1)
fisher.test(m1)
t.test(m1)
chisq.test(m1)
xsqtest$expected
xsqtest <- chisq.test(m1)
xsqtest$expected
# test if female is more than half the group
t.test(mydata)
?t.test
mydata$female
mydata
ftable(mydata)
# test if female is more than half the group
data1 <- ftable(mydata)
data1
sum(mydata)
sum(mydata)/2
sum(data1)
?sum
chisq.test(mydata)
prop.table(mydata)
data1
table(mydata)
table(data1)
mydata
mantelhaen.test(mydata)
# 10 students from 50 schools take a test
# passing rate of the test is 30%
# calculate a 95% confidence interval for each school
# and draw the interval line plot including the reference line
m = 50; n=10; p = .3;
phat = rbinom(m,n,p)/n
phat
SE = sqrt(phat*(1-phat)/n)
alpha = 0.05; zstar = qnorm(1-alpha/2)
matplot(rbind(phat - zstar*SE, phat + zstar*SE),
rbind(1:m,1:m),type="l",lty=1, xlab="Probability", ylab="")
abline(v=p)
rm(list=ls())
# 59 accidents during the weekend among 114 bicycle accidents
# test if the proportion of bicycle accidents during the weekend is less than .60
# report the p value with continutity correction
prop.test(59, 114, .6, alternative='less')
# determine the proportion of males with brown hair and green eyes
mydata <- datasets::HairEyeColor
prop.table(mydata)
# test if female is more than half the group
x=sum(HairEyeColor[,,Sex='Female'])
prop.test(x, sum(HairEyeColor), alternative='greater')
tbl <- table(survey$Smoke, survey$Exer)
# report test statisitc for data in table
library(MASS)
tbl <- table(survey$Smoke, survey$Exer)
chisq.test(tbl)
ctbl <- cbind(tbl[,'Freq'], tbl[,'None'] + tbl[,'Some'])
ctbl
tbl
tbchisq.test(ctbl)
chisq.test(ctbl)
xsqtest
# from the previous question, what is the expected value of row 1 col 1
xsqtest <- chisq.test(ctbl)
xsqtest$expected
rm(list=ls())
# 59 accidents during the weekend among 114 bicycle accidents
# test if the proportion of bicycle accidents during the weekend is less than .60
# report the p value with continutity correction
prop.test(59, 114, .6, alternative='less')
# 59 accidents during the weekend among 114 bicycle accidents
# test if the proportion of bicycle accidents during the weekend is less than .60
# report the p value with continutity correction
prop.test(59, 114, .6, alternative='less')
# determine the proportion of males with brown hair and green eyes
mydata <- datasets::HairEyeColor
prop.table(mydata)
# test if female is more than half the group
x <- sum(HairEyeColor[,,Sex='Female'])
prop.test(x, sum(HairEyeColor), alternative='greater')
# report test statisitc for data in table
library(MASS)
tbl <- table(survey$Smoke, survey$Exer) # contingency table
chisq.test(tbl)
ctbl <- cbind(tbl[,'Freq'], tbl[,'None'] + tbl[,'Some'])
ctbl
chisq.test(ctbl)
# from the previous question, what is the expected value of row 1 col 1
xsqtest <- chisq.test(ctbl)
xsqtest$expected
rm(list=ls())
setwd('~/Documents/RScripts')
# load in data
bigdata <- read.table('fat.dat.txt')
View(bigdata)
# rename columns
col_name <- c('CaseNum', '%BF_Brozek', '%BF_Siri', 'Density', 'Age', 'Weight', 'Height',
'Adip_Index', 'Neck_Circum', 'Chest_Circum', 'Abd_Circum', 'Hip_Circum',
'Thigh_Circum', 'Knee_Circum', 'Ankle_Circum', 'Ext_Bicep_Circum',
'Forearm_Circum', 'Wrist_Circum')
colnames(bigdata) <- col_name
View(bigdata)
rm(list=ls())
setwd('~/Documents/RScripts')
# load in data
bigdata <- read.table('fat.dat.txt')
# rename columns
col_name <- c('CaseNum', '%BF_Brozek', '%BF_Siri', 'Density', 'Age', 'Weight', 'Height',
'Adip_Index', 'Fat_Free_Weight','Neck_Circum', 'Chest_Circum', 'Abd_Circum', 'Hip_Circum',
'Thigh_Circum', 'Knee_Circum', 'Ankle_Circum', 'Ext_Bicep_Circum',
'Forearm_Circum', 'Wrist_Circum')
colnames(bigdata) <- col_name
View(bigdata)
# load in college.csv
college <- read.csv('college.csv')
View(college)
# look at data using the fix() function
rownames(college) = college[ ,1]
View(college)
rm(list=ls())
setwd('~/Documents/RScripts')
# load in data
bigdata <- read.table('fat.dat.txt')
# convert case numbers to row names
rownames(bigdata) = bigdata[ ,1]
bigdata <- bigdata[ ,-1]
View(bigdata)
# rename columns
col_name <- c('%BF_Brozek', '%BF_Siri', 'Density', 'Age', 'Weight', 'Height',
'Adip_Index', 'Fat_Free_Weight','Neck_Circum', 'Chest_Circum', 'Abd_Circum', 'Hip_Circum',
'Thigh_Circum', 'Knee_Circum', 'Ankle_Circum', 'Ext_Bicep_Circum',
'Forearm_Circum', 'Wrist_Circum')
colnames(bigdata) <- col_name
View(bigdata)
rm(list=ls())
setwd('~/Documents/GitHub/STAT7110Project')
