shapiro.test(mtcars$mpg)
wilcox.test(mtcars$mpg, mu=20)
wilcox.test(mtcars$mpg,
mu=20,
exact = F)
wilcox.test(mpg ~ am, exact=F, data=mtcars)
wilcox.test(extra ~ group, exact=F, paired = T, data=sleep)
cov(mtcars)
cor(mtcars)
cov(airquality)   # NA due to missing values
cov(airquality,
use = "complete.obs", # removes missing values
method = "pearson")
datasets::rock
mydata <- datasets::rock
View(mydata)
stat.desc(mydata, basic=TRUE, desc=TRUE, norm=FALSE, p=0.95)
stat.desc(mydata, basic=F, desc=F, norm=T)  # normal distribution stats only
# report the sd of the variable area when perm=100
values <- c(1468, 3524, 3469, 5267)
sd(values)
?t.test
# report p value the test whether the average area is less than 8000
result <- t.test(mydata$area, alternative='less')
result
mean(mydata$area)
# report p value the test whether the average area is less than 8000
result <- t.test(mydata$area, mu=8000, alternative='less')
result
stat.desc(mydata, basic=F) # descriptive stats only
stat.desc(mydata, basic=TRUE, desc=TRUE, norm=FALSE, p=0.95)
stat.desc(mydata, basic=F) # descriptive stats only
stat.desc(mydata, desc=F) # basic stats only
# 99% confidence interval of the population mean area
stat.desc(mydata, basic=F, p=.99)
# 99% confidence interval of the population mean area
stat.desc(mydata, basic=F, p=.99)
sapply(mydata, FUN=mean) # mean for every variable
sapply(mydata, FUN=mean, na.rm=T) # removing NA values
describe(mydata) # also gives basic statistics
summary(mydata)
?pastecs::stat.desc
# 99% confidence interval of the population mean area
t.test(mydata$area, mu=mean(mydata$area), p=.99)
?t.test
# 99% confidence interval of the population mean area
t.test(mydata$area, mu=mean(mydata$area), conf.level=.99)
# report the sd of the variable area when perm=100
values1 <- c(1468, 3524, 3469, 5267)
# report the p value whether the population mean area in perm=100 and perm=1300
# are the same or not
# test equal variances first
values2 <- c(1016, 5048, 5605, 8793)
bartlett.test(values1 ~ values2)
# which variables follow a normal distribution?
shapiro.test(mydata$area)
shapiro.test(mydata$peri)
shapiro.test(mydata$shape)
shapiro.test(mydata$perm)
# report the covariance between shape and perm
cov(mydata)
# report the covariance between shape and perm
cov(mydata)
# report pearson coefficient of correlation between shape and perm
cor(mydata)
stat.desc(mydata, basic=F, desc=F, norm=T)
# OR
sapply(mydata, FUN=skew)
bartlett.test(area ~ perm, data=mydata.all)
bartlett.test(area ~ perm, data=mydata)
# big p value, assume equal variance
t.test(area ~ perm, var.equal=TRUE, data=mydata)
# big p value, assume equal variance
t.test(area ~ perm, var.equal=TRUE, data=mydata.all)
mydata.all
###############
# Confidence Interval
# Toss 20 coins 50 times, compute proportions, and compute SE (standard error)
# example for central limit theorem
m = 100; n=20; p = .5;         # toss 20 coins 50 times
phat = rbinom(m,n,p)/n        # divide by n for proportions
rm(list=ls())
###############
# Confidence Interval
# Toss 20 coins 50 times, compute proportions, and compute SE (standard error)
# example for central limit theorem
m = 100; n=20; p = .5;         # toss 20 coins 50 times
phat = rbinom(m,n,p)/n        # divide by n for proportions
phat
SE = sqrt(phat*(1-phat)/n)    # compute standard error
round(SE, 4)
# Let alpha = 0.1 and plot CIs
alpha = 0.05; zstar = qnorm(1-alpha/2)
matplot(rbind(phat - zstar*SE, phat + zstar*SE),
rbind(1:m,1:m),type="l",lty=1, xlab="Probability", ylab="")
abline(v=p)                  # draw line for p=0.5
###############
# Simple frequency distribution
( tmp <- rpois(100, 5) )
table(tmp)
table(mtcars$cyl)
with(mtcars, table(cyl))
attach(mtcars)
( mytable <- table(cyl, gear) )
margin.table(mytable, 1) # 1 for rows: A frequencies (summed over B)
margin.table(mytable, 2) # 2 for columns: B frequencies (summed over A)
prop.table(mytable) # cell percentages
prop.table(mytable, 1) # row percentages
prop.table(mytable, 2) # column percentages
detach(mtcars)
###############
# 3-Way Frequency Table
example <- data.frame(
Hospital = sample(as.factor(paste("H",1:5)), size = 10, replace = TRUE),
Time = sample(as.factor(c(" 2000", " 2003", " 2006")), size = 10, replace = TRUE),
Nodes = sample(1:5, size = 10, replace = TRUE)
)
example
table(example)
ftable(example)
names(example)
Titanic
str(Titanic)
ftable(Titanic, row.vars = 1:3)
ftable(Titanic, row.vars = 1:2, col.vars = "Survived") # class and sex, column variable is survived only
ftable(Titanic, row.vars = 2:1, col.vars = "Survived") # change order of sex and class
## Start with a data frame.
x <- ftable(mtcars[c("cyl", "vs", "am", "gear")])
x
ftable(x, row.vars = c(2, 4))
library(gmodels)
CrossTable(example$Hospital, example$Time)
( heads <- rbinom(1, size=100, prob = .5) )  # p-hat=heads/size
?prop.test
prop.test(10, 100)          # continuity correction TRUE by default
prop.test(heads, 100, correct = FALSE)
prop.test(heads, 100, alternative="greater")
prop.test(heads, 100, alternative="less")
prop.test(heads, 100, alternative="two.sided")
prop.test(heads,100, conf.level=0.90)
prop.test(heads,100, conf.level=0.99)
( X <- c(A = 20, B = 15, C = 25) )
(Xsq <- chisq.test(X))  # Prints test summary
Xsq$observed   # observed counts (same as M)
Xsq$expected   # expected counts under the null
Xsq$residuals  # Pearson residuals
Xsq$stdres     # standardized residuals
Xsq$p.value
x <- c(59, 57, 16)
p <- c(.4, .5, .1)
chisq.test(x, p = p)
p <- c(4, 5, 1)
chisq.test(x, p=p, rescale.p=T)
x <- trunc(5 * runif(100))
x; table(x)
chisq.test(table(x))            # NOT 'chisq.test(x)'!
M <- as.table(rbind(c(762, 327, 468), c(484, 239, 477)))
dimnames(M) <- list(gender = c("M","F"),
party = c("Democrat","Independent", "Republican"))
M
(Xsq <- chisq.test(M))  # Prints test summary
Xsq$expected   # expected counts under the null
TeaTasting <-
matrix(c(3, 1, 1, 3),
nrow = 2,
dimnames = list(Guess = c("Milk", "Tea"),
Truth = c("Milk", "Tea")))
View(TeaTasting)
fisher.test(TeaTasting, alternative = "greater")
Job <- matrix(c(1,2,1,0, 3,3,6,1, 10,10,14,9, 6,7,12,11), 4, 4,
dimnames = list(income = c("< 15k", "15-25k", "25-40k", "> 40k"),
satisfaction = c("VeryD", "LittleD", "ModerateS", "VeryS")))
View(Job)
chisq.test(Job)
chisq.test(Job)$expected
fisher.test(Job)
###############
# Job Satisfaction example
# H0: there is no association by gender and income on job satisfaction
Satisfaction <-
as.table(array(c(1, 2, 0, 0, 3, 3, 1, 2,
11, 17, 8, 4, 2, 3, 5, 2,
1, 0, 0, 0, 1, 3, 0, 1,
2, 5, 7, 9, 1, 1, 3, 6),
dim = c(4, 4, 2),
dimnames =
list(Income =
c("<5000", "5000-15000",
"15000-25000", ">25000"),
"Job Satisfaction" =
c("V_D", "L_S", "M_S", "V_S"),
Gender = c("Female", "Male"))))
Satisfaction
## (Satisfaction categories abbreviated for convenience.)
ftable(. ~ Gender + Income, Satisfaction)
mantelhaen.test(Satisfaction)
mantelhaen.test(Satisfaction)
# big p value, no association between gender and income for job satisfaction
mantelhaen.test(Satisfaction)
# big p value, no association between gender and income for job satisfaction
# Does weight come from a normal with mean=120 and sd=15?
ks.test(women$weight, "pnorm", mean=120, sd=15)
# Does weight come from a normal with mean=135 and sd=15?
ks.test(women$weight, "pnorm", mean=135, sd=15)
# 59 accidents during the weekend among 114 bicycle accidents
# test if the proportion of bicycle accidents during the weekend is less than .60
# report the p value with continutity correction
prop.test(59, 114, correct=TRUE)
rm(list=ls())
# determine the proportion of males with brown hair and green eyes
mydata <- datasets::HairEyeColor
mydata
M <- as.table(rbind(c(762, 327, 468), c(484, 239, 477)))
dimnames(M) <- list(gender = c("M","F"),
party = c("Democrat","Independent", "Republican"))
M
###############
# Job Satisfaction example
# H0: there is no association by gender and income on job satisfaction
Satisfaction <-
as.table(array(c(1, 2, 0, 0, 3, 3, 1, 2,
11, 17, 8, 4, 2, 3, 5, 2,
1, 0, 0, 0, 1, 3, 0, 1,
2, 5, 7, 9, 1, 1, 3, 6),
dim = c(4, 4, 2),
dimnames =
list(Income =
c("<5000", "5000-15000",
"15000-25000", ">25000"),
"Job Satisfaction" =
c("V_D", "L_S", "M_S", "V_S"),
Gender = c("Female", "Male"))))
# three way table
Satisfaction
## (Satisfaction categories abbreviated for convenience.)
ftable(. ~ Gender + Income, Satisfaction)
# use this test for three way table
mantelhaen.test(Satisfaction)
ftable(. ~ Hair + Eyes, mydata)
?mantelhaen.test
mantelhaen.test(mydata)
table(mydata)
ftable(mydata)
ftable(mydata)
ftable(mydata)
names(mydata)
prop.table(mydata, 2)
prop.table(mydata)
prop.table(mydata)
# test if female is more than half the group
prop.test(mydata)
# test if female is more than half the group
ftable(mydata)
fisher.test(mydata,, alternative='greater')
fisher.test(mydata, alternative='greater')
chisq.test(mydata)
mydata
v1 <- c(7, 4, 87, 102, 12, 7, 9, 8)
?matrix
m1 <- maxtrix(v1, ncol=2)
m1 <- matrix(v1, ncol=2)
View(m1)
m1 <- matrix(v1, byrow=TRUE, ncol=2)
View(m1)
fisher.test(m1)
t.test(m1)
chisq.test(m1)
xsqtest$expected
xsqtest <- chisq.test(m1)
xsqtest$expected
# test if female is more than half the group
t.test(mydata)
?t.test
mydata$female
mydata
ftable(mydata)
# test if female is more than half the group
data1 <- ftable(mydata)
data1
sum(mydata)
sum(mydata)/2
sum(data1)
?sum
chisq.test(mydata)
prop.table(mydata)
data1
table(mydata)
table(data1)
mydata
mantelhaen.test(mydata)
# 10 students from 50 schools take a test
# passing rate of the test is 30%
# calculate a 95% confidence interval for each school
# and draw the interval line plot including the reference line
m = 50; n=10; p = .3;
phat = rbinom(m,n,p)/n
phat
SE = sqrt(phat*(1-phat)/n)
alpha = 0.05; zstar = qnorm(1-alpha/2)
matplot(rbind(phat - zstar*SE, phat + zstar*SE),
rbind(1:m,1:m),type="l",lty=1, xlab="Probability", ylab="")
abline(v=p)
rm(list=ls())
# 59 accidents during the weekend among 114 bicycle accidents
# test if the proportion of bicycle accidents during the weekend is less than .60
# report the p value with continutity correction
prop.test(59, 114, .6, alternative='less')
# determine the proportion of males with brown hair and green eyes
mydata <- datasets::HairEyeColor
prop.table(mydata)
# test if female is more than half the group
x=sum(HairEyeColor[,,Sex='Female'])
prop.test(x, sum(HairEyeColor), alternative='greater')
tbl <- table(survey$Smoke, survey$Exer)
# report test statisitc for data in table
library(MASS)
tbl <- table(survey$Smoke, survey$Exer)
chisq.test(tbl)
ctbl <- cbind(tbl[,'Freq'], tbl[,'None'] + tbl[,'Some'])
ctbl
tbl
tbchisq.test(ctbl)
chisq.test(ctbl)
xsqtest
# from the previous question, what is the expected value of row 1 col 1
xsqtest <- chisq.test(ctbl)
xsqtest$expected
rm(list=ls())
# 59 accidents during the weekend among 114 bicycle accidents
# test if the proportion of bicycle accidents during the weekend is less than .60
# report the p value with continutity correction
prop.test(59, 114, .6, alternative='less')
# 59 accidents during the weekend among 114 bicycle accidents
# test if the proportion of bicycle accidents during the weekend is less than .60
# report the p value with continutity correction
prop.test(59, 114, .6, alternative='less')
# determine the proportion of males with brown hair and green eyes
mydata <- datasets::HairEyeColor
prop.table(mydata)
# test if female is more than half the group
x <- sum(HairEyeColor[,,Sex='Female'])
prop.test(x, sum(HairEyeColor), alternative='greater')
# report test statisitc for data in table
library(MASS)
tbl <- table(survey$Smoke, survey$Exer) # contingency table
chisq.test(tbl)
ctbl <- cbind(tbl[,'Freq'], tbl[,'None'] + tbl[,'Some'])
ctbl
chisq.test(ctbl)
# from the previous question, what is the expected value of row 1 col 1
xsqtest <- chisq.test(ctbl)
xsqtest$expected
rm(list=ls())
setwd('~/Documents/GitHub/STAT7110Project')
# load in data
bigdata <- read.table('fat.dat.txt')
# convert case numbers to row names
rownames(bigdata) = bigdata[ ,1]
bigdata <- bigdata[ ,-1]
# rename columns
col_name <- c('%BF_Brozek', '%BF_Siri', 'Density', 'Age', 'Weight', 'Height',
'Adip_Index', 'Fat_Free_Weight','Neck_Circum', 'Chest_Circum', 'Abd_Circum', 'Hip_Circum',
'Thigh_Circum', 'Knee_Circum', 'Ankle_Circum', 'Ext_Bicep_Circum',
'Forearm_Circum', 'Wrist_Circum')
colnames(bigdata) <- col_name
View(bigdata)
plot(bigdata$Weight, bigdata$`%BF_Brozek`)
pairs(bigdata)
plot(bigdata$`%BF_Siri`, bigdata$`%BF_Brozek`)
# peaking at the data
str(bigdata)
View(bigdata)
summary(bigdata)
View(bigdata)
plot(bigdata$`%BF_Siri`, bigdata$Adip_Index)
plot(bigdata$`%BF_Brozek`, bigdata$Adip_Index)
plot(bigdata$`%BF_Siri`, bigdata$Fat_Free_Weight)
plot(bigdata$`%BF_Siri`, bigdata$Density)
plot(bigdata$`%BF_Siri`, bigdata$Height)
plot(bigdata$`%BF_Brozek`, bigdata$Weight)
plot(bigdata$`%BF_Siri`, bigdata$Age)
plot(bigdata$`%BF_Siri`, bigdata$Neck_Circum)
plot(bigdata$`%BF_Siri`, bigdata$Chest_Circum)
plot(bigdata$`%BF_Siri`, bigdata$Abd_Circum)
plot(bigdata$`%BF_Siri`, bigdata$Ext_Bicep_Circum)
plot(bigdata$`%BF_Siri`, bigdata$Hip_Circum)
plot(bigdata$`%BF_Siri`, bigdata$Thigh_Circum)
plot(bigdata$`%BF_Siri`, bigdata$Knee_Circum)
plot(bigdata$`%BF_Siri`, bigdata$Ankle_Circum)
plot(bigdata$`%BF_Siri`, bigdata$Forearm_Circum)
plot(bigdata$`%BF_Siri`, bigdata$Wrist_Circum)
plot(bigdata$Age, bigdata$Weight)
plot(bigdata$Height, bigdata$Weight)
plot(bigdata$Density, bigdata$Weight)
plot(bigdata$Density, bigdata$Height)
plot(bigdata$Density, bigdata$Weight)
plot(bigdata$Density, bigdata$Age)
plot(bigdata$Density, bigdata$Weight)
plot(bigdata$Weight, bigdata$Adip_Index)
pairs(bigdata)
# peaking at the data
str(bigdata)
summary(bigdata)
hist(bigdata$`%BF_Brozek`)
# distribution plot for BF%
hist(bigdata$`%BF_Brozek`, breaks=10, col="orange", border="dark green")
# distribution plot for BF%
hist(bigdata$`%BF_Brozek`, breaks=10, col="blue", border="dark green")
# distribution plot for BF%
hist(bigdata$`%BF_Brozek`, breaks=10, col="blue", border="white")
# distribution plot for BF%
hist(bigdata$`%BF_Brozek`, breaks=10, col="blue", border="white", prob=T)
lines(density(bigdata$`%BF_Brozek`))
# distribution plot for BF%
h <- hist(bigdata$`%BF_Brozek`, breaks=10,
main="Histogram with Normal Curve")
xfit <- seq(min(bigdata$`%BF_Brozek`), max(bigdata$`%BF_Brozek`), length=40) # 40 value of equal distance from min to max of mpg
yfit <- dnorm(xfit, mean=mean(bigdata$`%BF_Brozek`), sd=sd(bigdata$`%BF_Brozek`)) # normal density values for each x
yfit <- yfit*diff(h$mids[1:2])*length(bigdata$`%BF_Brozek`) # fitting
lines(xfit, yfit, col="blue", lwd=5)
hist(bigdata$`%BF_Brozek`, breaks=10, col="blue", border="white", prob=T)
lines(density(bigdata$`%BF_Brozek`))
title('Histogram of Brozek Percent Body Fat')
?hist
# distribution plot for BF%
hist(bigdata$`%BF_Brozek`, breaks=10, col="blue", border="white", prob=T,
main="Brozek's Body Fat Percentage", xlab="Brozek's Body Fat Percentage")
lines(density(bigdata$`%BF_Brozek`))
boxplot(bigdata$`%BF_Brozek`)
boxplot(bigdata$`%BF_Brozek`~bigdata$Age)
# scatter plots
plot(bigdata$`%BF_Brozek`, bigdata$Adip_Index)
# scatter plots
?plot
plot(bigdata$`%BF_Brozek`, bigdata$Adip_Index, xlab="Brozek's Body Fat (%)",
ylab='Adipose Index (kg/m^2)', main="Brozek's Body Fat Percentage vs Adipose Tissue Index")
abline()
?abline()
# scatter plots
plot(bigdata$`%BF_Brozek`, bigdata$Adip_Index, xlab="Brozek's Body Fat (%)",
ylab='Adipose Index (kg/m^2)', main="Brozek's Body Fat Percentage vs Adipose Tissue Index")
abline(lm(bigdata$`%BF_Brozek`~bigdata$Adip_Index), col="orange")
# scatter plot with trend line
ggplot(data = bidgata,
mapping = aes(x = '%BF_Brozek', y = Adip_Index)) +
geom_point(color = "cornflowerblue",
alpha = .7,
size = 3) +
geom_smooth(method = "lm")
# scatter plot with trend line
library(ggplot2)
ggplot(data = bidgata,
mapping = aes(x = '%BF_Brozek', y = Adip_Index)) +
geom_point(color = "cornflowerblue",
alpha = .7,
size = 3) +
geom_smooth(method = "lm")
ggplot(data = bigdata,
mapping = aes(x = '%BF_Brozek', y = Adip_Index)) +
geom_point(color = "cornflowerblue",
alpha = .7,
size = 3) +
geom_smooth(method = "lm")
ggplot(data = bigdata, mapping = aes(x = '%BF_Brozek', y = Adip_Index)) +
geom_point(color = "cornflowerblue", alpha = .7, size = 3) +
geom_smooth(method = "lm")
ggplot(data = bigdata, mapping = aes(x = '%BF_Brozek', y = Adip_Index)) +
geom_point(color = "cornflowerblue", alpha = .7, size = 3)
ggplot(data = bigdata, mapping = aes(x = bigdata$`%BF_Brozek`, y = Adip_Index)) +
geom_point(color = "cornflowerblue", alpha = .7, size = 3)
ggplot(data = bigdata, mapping = aes(x = bigdata$`%BF_Brozek`, y = Adip_Index)) +
geom_point(color = "cornflowerblue", alpha = .7, size = 3) +
geom_smooth(method = "lm")
ggplot(data = bigdata, mapping = aes(x = bigdata$`%BF_Brozek`, y = Adip_Index)) +
geom_point(color = "cornflowerblue", alpha = .7, size = 3) +
geom_smooth(method = "lm") +
labs(title = "Brozek's Body Fat Percentage vs Adipose Tissue Index",
x = "Brozek's Body Fat (%)",
y = "Adipose Index (kg/m^2)")
plot(bigdata$`%BF_Brozek`, bigdata$Height)
plot(bigdata$`%BF_Brozek`, bigdata$Weight)
# BF% and Weight
ggplot(data = bigdata, mapping = aes(x = bigdata$`%BF_Brozek`, y = Weight)) +
geom_point(color = "green", alpha = .7, size = 3) +
geom_smooth(method = "lm") +
labs(title = "Brozek's Body Fat Percentage vs Weight",
x = "Brozek's Body Fat (%)",
y = "Weight (lbs)")
# BF% and Weight
ggplot(data = bigdata, mapping = aes(x = bigdata$`%BF_Brozek`, y = Weight)) +
geom_point(color = "dark green", alpha = .7, size = 3) +
geom_smooth(method = "lm") +
labs(title = "Brozek's Body Fat Percentage vs Weight",
x = "Brozek's Body Fat (%)",
y = "Weight (lbs)")
plot(bigdata$`%BF_Siri`, bigdata$Chest_Circum)
plot(bigdata$`%BF_Siri`, bigdata$Abd_Circum)
plot(bigdata$`%BF_Siri`, bigdata$Hip_Circum)
# BF% and Abdomen Circumference
ggplot(data = bigdata, mapping = aes(x = bigdata$`%BF_Brozek`, y = Abd_Circum)) +
geom_point(color = "purple", alpha = .7, size = 3) +
geom_smooth(method = "lm") +
labs(title = "Brozek's Body Fat Percentage vs Abdomen Circumference",
x = "Brozek's Body Fat (%)",
y = "Abdomen Circumference (cm)")
plot(bigdata$Weight, bigdata$Adip_Index)
plot(bigdata$Density, bigdata$Weight)
plot(bigdata$Weight, bigdata$Adip_Index)
cov(bigdata)
#correlation of variables
cor(bigdata)
?cov
